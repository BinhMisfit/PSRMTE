{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Finalized MoE.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xMC2Xp6IxQLF","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1589956208996,"user_tz":-420,"elapsed":5808,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"280409e3-f3a9-465d-aebc-35a210b0df3d"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"gt2W5QSOxOBg"},"source":["from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","import re\n","ps = PorterStemmer()\n","stopwords=['the','of','and',  'in',  'is',  'to',  'for',  'we',  'are',  'that',  'with',  'this',  'on',  'by',  'an',  'as',  'be',  'which',  \n","'it',  'problem',  'two',  'from',  'can',  'results',  'paper',  'method',  'these',  'some',  'also',  'model',  'based',  'at',  'one',  \n","'show',  'such',  'using',  'or',  'has',  'time',  'system',  'order',  'new',  'solution',  'not',  'have',  'set',  'function',  'if',  'all',  \n","'our',  'finite',  'space',  'algorithm',  'its',  'number',  'solutions',  'problems',  'used',  'between',  'given',  'equations',  'where',  \n","'under',  'prove',  'functions',  'proposed',  'non',  'case',  'when',  'paper,',  'conditions',  'their',  'then',  'dimensional',  'class',  \n","'first',  'theory',  'general',  'well', 'other', 'models', 'may',  'were', 'they', 'so', 'et',   'al', 'no', 'very', 'those',   'due', 'however', \n","'di',    'moreover', 'here', 'i.e.']\n","def preprocess_text(text):\n","    text =re.sub(\"\\$\\$.*?\\$\\$\", \"\", text)\n","    text =re.sub(r\"http[^ ]*\", \"\", text)\n","    text =re.sub(\"\\$.*?\\$\", \"\", text)\n","    text =re.sub(\"\\\\\\\\\\(.*?\\\\\\\\\\)\", \"\", text)\n","    text =re.sub(\"\\\\\\\\\\[.*?\\\\\\\\\\]\", \"\", text)\n","    text =re.sub(\"\\[.*?\\]\", \"\", text)\n","    text =re.sub(\"{.*?}\", \"\", text)\n","    text =re.sub(r\"\\\\begin.*?\\\\end\", \"\", text)\n","    text=text.lower()\n","    text = re.sub(\"[^a-z \\-]\", \"\", text)\n","    text= word_tokenize(text)\n","    text = [word for word in text if not word in stopwords] # remove stopwords\n","    text=[ps.stem(word) for word in text]\n","    text=\" \".join(text)\n","    text=' '.join([item for item in  text.split(' ') if len(item) >= 2])\n","    return text\n","def preprocess_keywords(text):\n","    text=text.lower()\n","    text = re.sub(\"[^a-z \\-]\", \"\", text)\n","    text=' '.join([item for item in  text.split(' ') if len(item) >= 2])\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pkt0AfQRxOBm"},"source":["with open(\"springer_train_processed.jsonl\", \"rt\") as infile:\n","    import json\n","    train = []\n","    for line in infile:\n","        train.append(json.loads(line))\n","with open(\"springer_valid_processed.jsonl\", \"rt\") as infile:\n","    import json\n","    valid = []\n","    for line in infile:\n","        valid.append(json.loads(line))\n","with open(\"springer_test_processed.jsonl\", \"rt\") as infile:\n","    import json\n","    test = []\n","    for line in infile:\n","        test.append(json.loads(line))\n","journals = list(set([item[\"journal\"] for item in train]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hz46GxbxOBp"},"source":["\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","# extracting features\n","#df is data\n","#name is one of Abstract, Title, Keywords\n","def chi(dataset,feature, categories): \n","    \n","    vocabulary=[]         #Dictionary contains chi-value of every word belong to certain category \n","\n","    for category in categories:\n","      #print(i)\n","      doc_cate, doc_not_cate = [], []\n","      for item in dataset:\n","        if item['journal'] == category: doc_cate.append(item[feature])\n","        else: doc_not_cate.append(item[feature])\n","\n","      counter_cate =  CountVectorizer(binary=True,lowercase = True,ngram_range=(1,1))             \n","      X_dtm = counter_cate.fit_transform(doc_cate)\n","      counter_not_cate= CountVectorizer(binary=True,lowercase = True,ngram_range=(1,1),vocabulary=counter_cate.get_feature_names())  \n","      \n","      A = np.sum(X_dtm.toarray(),axis=0)\n","      B = counter_not_cate.fit_transform(doc_not_cate)\n","      B = np.sum(B.toarray(),axis=0)\n","      n_item_cate = sum(item[\"journal\"] == category for item in dataset)\n","      C=n_item_cate*np.ones([1,len(A)])\n","      D=(len(dataset) - n_item_cate)*np.ones([1,len(B)])\n","      C=C[0]-A\n","      D=D[0]-B\n","      result=((A+B+C+D)*(A*D-B*C)**2)/((A+C)*(B+D)*(A+B)*(C+D))\n","     \n","      vocabulary.append(list(zip(counter_cate.get_feature_names(),result)))\n","      del doc_cate,doc_not_cate,counter_cate,counter_not_cate,X_dtm,A,B,C,D,result\n","    return vocabulary\n","\n","def get_top_vocabulary(categories, chisquares, topk=50, threshold=200):\n","    \n","    vocabulary=[]\n","    for ii in range(len(categories)):\n","        for word, val in sorted(chisquares[ii], key=lambda item: item[1],reverse=True)[:topk]:\n","            if val > threshold:\n","                vocabulary.append(word)\n","    vocabulary= list(set(vocabulary))\n","    return vocabulary\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxUB7URtxOBu"},"source":["def tf_idf(train,valid, test,feature,vocabuary): #name is a string\n","    tfidf = TfidfVectorizer(vocabulary=vocabuary, ngram_range=(1,1), dtype=np.float32)\n","    tfidf.fit([item[feature] for item in train])\n","    \n","    Vector_Train=tfidf.transform([item[feature] for item in train])\n","    Vector_train=Vector_Train.toarray()\n","\n","    Vector_Test=tfidf.transform([item[feature] for item in test])\n","    Vector_test=Vector_Test.toarray()\n","\n","    Vector_Valid=tfidf.transform([item[feature] for item in valid])\n","    Vector_valid=Vector_Valid.toarray()\n","    return Vector_train, Vector_valid, Vector_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4JrgIN6ExOBx"},"source":["import pickle\n","with open(\"springer_abstract_chisquares.pickle\", \"rb\") as infile:\n","    chisquares = pickle.load(infile)\n","\n","vocab = get_top_vocabulary(journals, chisquares,topk =50, threshold=0.0)\n","len(vocab)\n","train_abstract, valid_abstract, test_abstract = tf_idf(train,valid,test,\"abstract\",vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cudSctwLxOBz"},"source":["springer_labels = [\n","  'environmental modeling & assessment',\n","  'korean journal of computational and applied mathematics',\n","  'annali dell’università di ferrara',\n","  'differential equations and dynamical systems',\n","  'journal of applied and industrial mathematics',\n","  'set-valued analysis',\n","  'geometric & functional analysis gafa',\n","  'computational particle mechanics',\n","  'information systems frontiers',\n","  'computational and applied mathematics',\n","  'semigroup forum',\n","  'moscow university mathematics bulletin',\n","  'computational mechanics',\n","  'educational studies in mathematics',\n","  'applied mathematics',\n","  'memetic computing',\n","  'nonrenewable resources',\n","  'telecommunication systems',\n","  'annals of operations research',\n","  'journal of automated reasoning',\n","  'quarterly journal of the belgian, french and italian operations research societies',\n","  'integral equations and operator theory',\n","  'computing and visualization in science',\n","  'allgemeines statistisches archiv',\n","  'logica universalis',\n","  'proceedings of the steklov institute of mathematics',\n","  'acta applicandae mathematica',\n","  'fuzzy optimization and decision making',\n","  'evolutionary intelligence',\n","  'journal of geometry',\n","  'rendiconti del circolo matematico di palermo',\n","  'opsearch',\n","  'mathematics in computer science',\n","  'automation and remote control',\n","  'top',\n","  'bulletin of the malaysian mathematical sciences society',\n","  'mathematical models and computer simulations',\n","  'journal of optimization theory and applications',\n","  'minds and machines',\n","  'mathematics of control, signals and systems',\n","  'journal of soviet mathematics',\n","  'queueing systems',\n","  'racsam - revista de la real academia de ciencias exactas, fisicas y naturales. serie a. matematicas',\n","  'calcolo',\n","  'potential analysis',\n","  'doklady mathematics',\n","  'inventiones mathematicae',\n","  \"publications mathématiques de l'institut des hautes études scientifiques\",\n","  'operations-research-spektrum',\n","  'nonlinear differential equations and applications nodea',\n","  'p-adic numbers, ultrametric analysis, and applications',\n","  'sema journal',\n","  'journal of fourier analysis and applications',\n","  'arabian journal of mathematics',\n","  'analysis and mathematical physics',\n","  'mediterranean journal of mathematics',\n","  'computational optimization and applications',\n","  'siberian advances in mathematics',\n","  'journal of algebraic combinatorics',\n","  'the journal of the astronautical sciences',\n","  'general relativity and gravitation',\n","  'environmentalist',\n","  'foundations of computational mathematics',\n","  'revista matemática complutense',\n","  'science in china series a: mathematics',\n","  'annals of combinatorics',\n","  'ricerche di matematica',\n","  'numerical algorithms',\n","  'structural optimization',\n","  'journal of theoretical probability',\n","  'algebra and logic',\n","  'algebra universalis',\n","  'theoretical and mathematical physics',\n","  'russian mathematics',\n","  'communications in mathematical physics',\n","  'mathematical programming computation',\n","  'journal of global optimization',\n","  'annali di matematica pura ed applicata',\n","  'letters in mathematical physics',\n","  'jahresbericht der deutschen mathematiker-vereinigung',\n","  'statistical inference for stochastic processes',\n","  'zdm',\n","  'calculus of variations and partial differential equations',\n","  'journal of control theory and applications',\n","  'statistische hefte',\n","  'vietnam journal of mathematics',\n","  'mathematical programming',\n","  'energy systems',\n","  'boletín de la sociedad matemática mexicana',\n","  'journal of evolution equations',\n","  'journal of nonlinear science',\n","  'international journal of applied and computational mathematics',\n","  'lobachevskii journal of mathematics',\n","  'mathematics and financial economics',\n","  'complex analysis and operator theory',\n","  'computational statistics',\n","  'metrika',\n","  'computational complexity',\n","  'unternehmensforschung',\n","  'annales des télécommunications',\n","  'foundations of science',\n","  'experimental economics',\n","  'optimization and engineering',\n","  'operational research',\n","  'computational geosciences',\n","  'journal of fixed point theory and applications',\n","  'discrete event dynamic systems',\n","  'advances in applied clifford algebras',\n","  'collectanea mathematica',\n","  'computational methods and function theory',\n","  'international journal of game theory',\n","  'rendiconti del seminario matematico e fisico di milano',\n","  'combinatorica',\n","  'computational mathematics and mathematical physics',\n","  'acta mathematica sinica',\n","  'annals of finance',\n","  'journal of combinatorial optimization',\n","  'neural computing & applications',\n","  'japan journal of applied mathematics',\n","  'mathematical sciences',\n","  'dynamic games and applications',\n","  'cryptography and communications',\n","  'constraints',\n","  'advances in computational mathematics',\n","  'analysis mathematica',\n","  'applied mathematics and mechanics',\n","  'engineering with computers',\n","  'beiträge zur algebra und geometrie / contributions to algebra and geometry',\n","  'journal of engineering mathematics',\n","  'journal d’analyse mathématique',\n","  'european actuarial journal',\n","  'journal of scheduling',\n","  'annals of mathematics and artificial intelligence',\n","  'mathematische zeitschrift',\n","  'international journal of fuzzy systems',\n","  'journal of scientific computing',\n","  'zeitschrift für nationalökonomie',\n","  'modeling earth systems and environment',\n","  'numerische mathematik',\n","  'journal of dynamical and control systems',\n","  'theoretical and computational fluid dynamics',\n","  'interdisciplinary sciences: computational life sciences',\n","  'acta mathematica vietnamica',\n","  'journal of statistical theory and practice',\n","  'soviet applied mechanics',\n","  'discrete & computational geometry',\n","  'the ramanujan journal',\n","  'positivity',\n","  'mathematische annalen',\n","  'qualitative theory of dynamical systems',\n","  'regular and chaotic dynamics',\n","  'journal of cryptology',\n","  'israel journal of mathematics',\n","  'journal of mathematical biology',\n","  'social network analysis and mining',\n","  'results in mathematics',\n","  'journal of heuristics',\n","  'annales henri poincaré',\n","  'journal of systems science and complexity',\n","  'multibody system dynamics',\n","  'soft computing',\n","  'mathematical physics, analysis and geometry',\n","  'journal of mathematical imaging and vision',\n","  'selecta mathematica',\n","  'kn - journal of cartography and geographic information',\n","  'journal of dynamics and differential equations',\n","  'periodica mathematica hungarica',\n","  'computational management science',\n","  'journal of the operations research society of china',\n","  \"bollettino dell'unione matematica italiana\",\n","  'siberian mathematical journal',\n","  'numerical analysis and applications',\n","  'the journal of geometric analysis',\n","  'journal of quantitative economics',\n","  'computational mathematics and modeling',\n","  'mathematical notes of the academy of sciences of the ussr',\n","  'european journal of mathematics',\n","  'transformation groups',\n","  'cybernetics',\n","  'quantum information processing',\n","  'monatshefte für mathematik und physik',\n","  'afrika matematika',\n","  'archiv für mathematische logik und grundlagenforschung',\n","  'optimization letters',\n","  'economic theory bulletin',\n","  'constructive approximation',\n","  'functional analysis and its applications',\n","  'theory in biosciences',\n","  'journal of pseudo-differential operators and applications',\n","  'stochastic hydrology and hydraulics',\n","  'moscow university computational mathematics and cybernetics',\n","  'theory and decision',\n","  'vestnik st. petersburg university: mathematics',\n","  'bit numerical mathematics',\n","  'applied mathematics and optimization',\n","  'celestial mechanics']\n","\n","journal_to_idx = {journal:ii for ii, journal in enumerate(springer_labels)}\n","\n","y_train = np.asarray([journal_to_idx[item[\"journal\"].lower()] for item in train])\n","y_valid = np.asarray([journal_to_idx[item[\"journal\"].lower()] for item in valid])\n","y_test = np.asarray([journal_to_idx[item[\"journal\"].lower()] for item in test])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQZdRsrZxOB2"},"source":["import numpy as np\n","\n","def get_accuracy(y_true, y_pred):\n","    top1 = np.mean(np.repeat(y_true, 1).reshape(-1,1) == np.argsort(y_pred, axis=-1)[:,:-2:-1])*1\n","    top3 = np.mean(np.repeat(y_true, 3).reshape(-1,3) == np.argsort(y_pred, axis=-1)[:,:-4:-1])*3\n","    top5 = np.mean(np.repeat(y_true, 5).reshape(-1,5) == np.argsort(y_pred, axis=-1)[:,:-6:-1])*5\n","    top10 = np.mean(np.repeat(y_true, 10).reshape(-1,10) == np.argsort(y_pred, axis=-1)[:,:-11:-1])*10\n","    return [top1, top3, top5, top10]\n","def softmax_func(logits):\n","    return np.exp(logits) / np.sum(np.exp(logits), axis=1).reshape(-1,1)\n","\n","# train_softmaxes = []\n","valid_softmaxes = []\n","test_softmaxes = []\n","features = \"abstract\"\n","for model in ['scibert', 'xlnet', 'electra']:\n","    softmax = np.load(\"softmaxes/springer-{}-{}-valid.npy\".format(model, features)).astype(np.float32)\n","    if model in ['xlnet', 'electra']: \n","        softmax = softmax_func(softmax)\n","    valid_softmaxes.append(softmax)\n","\n","    softmax = np.load(\"softmaxes/springer-{}-{}-test.npy\".format(model, features)).astype(np.float32)\n","    if model in ['xlnet', 'electra']: \n","        softmax = softmax_func(softmax)\n","    test_softmaxes.append(softmax)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ej6EjswAxOB5","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1589956692582,"user_tz":-420,"elapsed":1071,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"5029bb30-c675-4e52-fecf-676a3cc1927a"},"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Dropout, Lambda, Concatenate, Reshape, Multiply\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","\n","input_tfidf = Input(shape=(train_abstract.shape[1], ))\n","xx = Dense(units=300, activation='relu')(input_tfidf)\n","transfer_softmax = Dense(units=196, activation='softmax')(xx)\n","transfer_model = Model(inputs=[input_tfidf], outputs=transfer_softmax)\n","\n","transfer_model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","transfer_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_12 (InputLayer)        [(None, 7534)]            0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 300)               2260500   \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 196)               58996     \n","=================================================================\n","Total params: 2,319,496\n","Trainable params: 2,319,496\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MNLxh2rexOB7","colab":{"base_uri":"https://localhost:8080/","height":901},"executionInfo":{"status":"ok","timestamp":1589956878618,"user_tz":-420,"elapsed":186872,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"5eab5712-5318-4e60-825e-c8506c6da368"},"source":["class ModelCheckpoint(tf.keras.callbacks.Callback):\n","\n","    def __init__(self, max_no_improvements=20):\n","        super(ModelCheckpoint, self).__init__()\n","        self.best_val_acc = 0.0\n","        self.best_weights = None\n","        self.max_no_improvements = max_no_improvements\n","        self.n_no_improvements = 0\n","\n","    def on_epoch_end(self, epoch, logs):\n","        val_acc = logs[\"val_acc\"]\n","        if self.best_weights is None or val_acc >= self.best_val_acc:\n","            self.best_weights = self.model.get_weights()\n","            self.best_val_acc = val_acc\n","            self.n_no_improvements = 0\n","        else:\n","            self.n_no_improvements += 1\n","            if self.n_no_improvements > self.max_no_improvements:\n","                self.model.stop_training = True\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 193892 samples, validate on 14945 samples\n","Epoch 1/1000\n","193892/193892 [==============================] - 8s 39us/sample - loss: 2.8517 - acc: 0.3452 - val_loss: 8.0186 - val_acc: 0.0141\n","Epoch 2/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 2.1619 - acc: 0.4481 - val_loss: 8.5713 - val_acc: 0.0136\n","Epoch 3/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.9994 - acc: 0.4771 - val_loss: 8.9340 - val_acc: 0.0134\n","Epoch 4/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.8885 - acc: 0.4984 - val_loss: 9.2265 - val_acc: 0.0143\n","Epoch 5/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.7997 - acc: 0.5163 - val_loss: 9.5005 - val_acc: 0.0130\n","Epoch 6/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.7229 - acc: 0.5318 - val_loss: 9.7529 - val_acc: 0.0130\n","Epoch 7/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.6550 - acc: 0.5460 - val_loss: 9.9894 - val_acc: 0.0128\n","Epoch 8/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.5930 - acc: 0.5600 - val_loss: 10.2303 - val_acc: 0.0130\n","Epoch 9/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.5357 - acc: 0.5743 - val_loss: 10.5152 - val_acc: 0.0129\n","Epoch 10/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.4831 - acc: 0.5868 - val_loss: 10.7894 - val_acc: 0.0131\n","Epoch 11/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.4324 - acc: 0.5994 - val_loss: 11.0196 - val_acc: 0.0133\n","Epoch 12/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.3855 - acc: 0.6126 - val_loss: 11.3034 - val_acc: 0.0130\n","Epoch 13/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.3392 - acc: 0.6245 - val_loss: 11.5724 - val_acc: 0.0132\n","Epoch 14/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.2954 - acc: 0.6374 - val_loss: 11.9021 - val_acc: 0.0130\n","Epoch 15/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.2535 - acc: 0.6488 - val_loss: 12.1539 - val_acc: 0.0134\n","Epoch 16/1000\n","193892/193892 [==============================] - 8s 40us/sample - loss: 1.2126 - acc: 0.6607 - val_loss: 12.4567 - val_acc: 0.0134\n","Epoch 17/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.1739 - acc: 0.6721 - val_loss: 12.7494 - val_acc: 0.0125\n","Epoch 18/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.1359 - acc: 0.6834 - val_loss: 13.0634 - val_acc: 0.0138\n","Epoch 19/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.0997 - acc: 0.6944 - val_loss: 13.3296 - val_acc: 0.0126\n","Epoch 20/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.0649 - acc: 0.7051 - val_loss: 13.6384 - val_acc: 0.0133\n","Epoch 21/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 1.0305 - acc: 0.7150 - val_loss: 13.9352 - val_acc: 0.0128\n","Epoch 22/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 0.9983 - acc: 0.7258 - val_loss: 14.2787 - val_acc: 0.0134\n","Epoch 23/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 0.9666 - acc: 0.7354 - val_loss: 14.5856 - val_acc: 0.0127\n","Epoch 24/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 0.9363 - acc: 0.7442 - val_loss: 14.9233 - val_acc: 0.0132\n","Epoch 25/1000\n","193892/193892 [==============================] - 7s 38us/sample - loss: 0.9068 - acc: 0.7527 - val_loss: 15.2354 - val_acc: 0.0132\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7b77429ac8>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"4HeAzMq_LBY1"},"source":["transfer_model.fit([train_abstract], \n","          y_train, \n","          epochs=1000, \n","          batch_size=128, \n","          callbacks= [ModelCheckpoint()],\n","          validation_data=([valid_abstract], y_valid))\n","# get_accuracy(y_train, transfer_model.predict([train_abstract]))"],"execution_count":null,"outputs":[]}]}