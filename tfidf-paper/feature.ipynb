{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"feature.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZidKvXrFJyzf"},"source":["# Load library and Dataset"]},{"cell_type":"code","metadata":{"id":"qaPIc9w3E7Zt","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1589891339033,"user_tz":-420,"elapsed":74419,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"0bf873f0-0aee-40f1-d796-b30906f89cd3"},"source":["%tensorflow_version 1.x\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 144433 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.21-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.21-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.21-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RXCO_eKHagni"},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/tfidf-paper/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5X2Xsnw9iTQf","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1589891345767,"user_tz":-420,"elapsed":80000,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"36c897d6-690a-4bbf-f7c5-65a55e1661de"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"yPfn2dLliDWX"},"source":["from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","import re\n","ps = PorterStemmer()\n","stopwords=['the','of','and',  'in',  'is',  'to',  'for',  'we',  'are',  'that',  'with',  'this',  'on',  'by',  'an',  'as',  'be',  'which',  \n","'it',  'problem',  'two',  'from',  'can',  'results',  'paper',  'method',  'these',  'some',  'also',  'model',  'based',  'at',  'one',  \n","'show',  'such',  'using',  'or',  'has',  'time',  'system',  'order',  'new',  'solution',  'not',  'have',  'set',  'function',  'if',  'all',  \n","'our',  'finite',  'space',  'algorithm',  'its',  'number',  'solutions',  'problems',  'used',  'between',  'given',  'equations',  'where',  \n","'under',  'prove',  'functions',  'proposed',  'non',  'case',  'when',  'paper,',  'conditions',  'their',  'then',  'dimensional',  'class',  \n","'first',  'theory',  'general',  'well', 'other', 'models', 'may',  'were', 'they', 'so', 'et',   'al', 'no', 'very', 'those',   'due', 'however', \n","'di',    'moreover', 'here', 'i.e.']\n","def preprocess_text(text):\n","    text =re.sub(\"\\$\\$.*?\\$\\$\", \"\", text)\n","    text =re.sub(r\"http[^ ]*\", \"\", text)\n","    text =re.sub(\"\\$.*?\\$\", \"\", text)\n","    text =re.sub(\"\\\\\\\\\\(.*?\\\\\\\\\\)\", \"\", text)\n","    text =re.sub(\"\\\\\\\\\\[.*?\\\\\\\\\\]\", \"\", text)\n","    text =re.sub(\"\\[.*?\\]\", \"\", text)\n","    text =re.sub(\"{.*?}\", \"\", text)\n","    text =re.sub(r\"\\\\begin.*?\\\\end\", \"\", text)\n","    text=text.lower()\n","    text = re.sub(\"[^a-z \\-]\", \"\", text)\n","    text= word_tokenize(text)\n","    text = [word for word in text if not word in stopwords] # remove stopwords\n","    text=[ps.stem(word) for word in text]\n","    text=\" \".join(text)\n","    text=' '.join([item for item in  text.split(' ') if len(item) >= 2])\n","    return text\n","def preprocess_keywords(text):\n","    text=text.lower()\n","    text = re.sub(\"[^a-z \\-]\", \"\", text)\n","    text=' '.join([item for item in  text.split(' ') if len(item) >= 2])\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fUDicnr7gFnZ"},"source":["# import json\n","# with open(\"../electra-paper/springer-paper/train.jsonl\") as infile:\n","#     train = []\n","#     for item in infile:\n","#         item = json.loads(item)\n","#         item['title'] = preprocess_text(item['title'])\n","#         item['abstract'] = preprocess_text(item['abstract'])\n","#         if type(item[\"keywords\"]) is str:\n","#             item['keywords'] = preprocess_keywords(item['keywords'])\n","#         item['journal'] = item['journal'].lower()\n","\n","#         train.append(item)\n","\n","# with open(\"../electra-paper/springer-paper/valid.jsonl\") as infile:\n","#     valid = []\n","#     for item in infile:\n","#         item = json.loads(item)\n","#         item['title'] = preprocess_text(item['title'])\n","#         item['abstract'] = preprocess_text(item['abstract'])\n","#         if type(item[\"keywords\"]) is str:\n","#             item['keywords'] = preprocess_keywords(item['keywords'])\n","#         item['journal'] = item['journal'].lower()\n","\n","#         valid.append(item)\n","\n","# with open(\"../electra-paper/springer-paper/test.jsonl\") as infile:\n","#     test = []\n","#     for item in infile:\n","#         item = json.loads(item)\n","#         item['title'] = preprocess_text(item['title'])\n","#         item['abstract'] = preprocess_text(item['abstract'])\n","#         if type(item[\"keywords\"]) is str:\n","#             item['keywords'] = preprocess_keywords(item['keywords'])\n","#         item['journal'] = item['journal'].lower()\n","\n","#         test.append(item)\n","\n","# journals = list(set([item[\"journal\"] for item in train]))\n","# journal_to_idx = {journal: ii for ii, journal in enumerate(journals)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"npjhSg7gK8W8"},"source":["with open(\"springer_train_processed.jsonl\", \"rt\") as infile:\n","    import json\n","    train = []\n","    for line in infile:\n","        train.append(json.loads(line))\n","with open(\"springer_valid_processed.jsonl\", \"rt\") as infile:\n","    import json\n","    valid = []\n","    for line in infile:\n","        valid.append(json.loads(line))\n","with open(\"springer_test_processed.jsonl\", \"rt\") as infile:\n","    import json\n","    test = []\n","    for line in infile:\n","        test.append(json.loads(line))\n","journals = list(set([item[\"journal\"] for item in train]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vc6UYSQSZ-Jb"},"source":["\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","# extracting features\n","#df is data\n","#name is one of Abstract, Title, Keywords\n","def chi(dataset,feature, categories): \n","    \n","    vocabulary=[]         #Dictionary contains chi-value of every word belong to certain category \n","\n","    for category in categories:\n","      #print(i)\n","      doc_cate, doc_not_cate = [], []\n","      for item in dataset:\n","        if item['journal'] == category: doc_cate.append(item[feature])\n","        else: doc_not_cate.append(item[feature])\n","\n","      counter_cate =  CountVectorizer(binary=True,lowercase = True,ngram_range=(1,1))             \n","      X_dtm = counter_cate.fit_transform(doc_cate)\n","      counter_not_cate= CountVectorizer(binary=True,lowercase = True,ngram_range=(1,1),vocabulary=counter_cate.get_feature_names())  \n","      \n","      A = np.sum(X_dtm.toarray(),axis=0)\n","      B = counter_not_cate.fit_transform(doc_not_cate)\n","      B = np.sum(B.toarray(),axis=0)\n","      n_item_cate = sum(item[\"journal\"] == category for item in dataset)\n","      C=n_item_cate*np.ones([1,len(A)])\n","      D=(len(dataset) - n_item_cate)*np.ones([1,len(B)])\n","      C=C[0]-A\n","      D=D[0]-B\n","      result=((A+B+C+D)*(A*D-B*C)**2)/((A+C)*(B+D)*(A+B)*(C+D))\n","     \n","      vocabulary.append(list(zip(counter_cate.get_feature_names(),result)))\n","      del doc_cate,doc_not_cate,counter_cate,counter_not_cate,X_dtm,A,B,C,D,result\n","    return vocabulary\n","\n","def get_top_vocabulary(categories, chisquares, topk=50, threshold=200):\n","    \n","    vocabulary=[]\n","    for ii in range(len(categories)):\n","        for word, val in sorted(chisquares[ii], key=lambda item: item[1],reverse=True)[:topk]:\n","            if val > threshold:\n","                vocabulary.append(word)\n","    vocabulary= list(set(vocabulary))\n","    return vocabulary\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9ZzDevxfN4q"},"source":["# abstract_chisquares = chi(train, \"abstract\", journals)\n","\n","# import pickle\n","# with open(\"springer_abstract_chisquares.pickle\", \"wb\") as outfile:\n","#     pickle.dump(abstract_chisquares, outfile)\n","\n","# title_chisquares = chi(train, \"title\", journals)\n","\n","# import pickle\n","# with open(\"springer_title_chisquares.pickle\", \"wb\") as outfile:\n","#     pickle.dump(title_chisquares, outfile)\n","\n","# keywords_chisquares = chi(train, \"keywords\", journals)\n","\n","# import pickle\n","# with open(\"springer_keywords_chisquares.pickle\", \"wb\") as outfile:\n","#     pickle.dump(keywords_chisquares, outfile)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLMs5jCC8cav"},"source":["def tf_idf(train,valid, test,feature,vocabuary): #name is a string\n","    tfidf = TfidfVectorizer(vocabulary=vocabuary, ngram_range=(1,1), dtype=np.float32)\n","    tfidf.fit([item[feature] for item in train])\n","    \n","    Vector_Train=tfidf.transform([item[feature] for item in train])\n","    Vector_train=Vector_Train.toarray()\n","\n","    Vector_Test=tfidf.transform([item[feature] for item in test])\n","    Vector_test=Vector_Test.toarray()\n","\n","    Vector_Valid=tfidf.transform([item[feature] for item in valid])\n","    Vector_valid=Vector_Valid.toarray()\n","    return Vector_train, Vector_valid, Vector_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k3PMJk4Kfzop"},"source":["import pickle\n","with open(\"springer_abstract_chisquares.pickle\", \"rb\") as infile:\n","    chisquares = pickle.load(infile)\n","\n","vocab = get_top_vocabulary(journals, chisquares,topk =50, threshold=0.0)\n","len(vocab)\n","train_abstract, valid_abstract, test_abstract = tf_idf(train,valid,test,\"abstract\",vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5EQ2pCUE7Z0","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589878037804,"user_tz":-420,"elapsed":9308,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"dab8c07b-e927-4dfa-d173-ddfdc17934f1"},"source":["import pickle\n","with open(\"springer_title_chisquares.pickle\", \"rb\") as infile:\n","    chisquares = pickle.load(infile)\n","\n","vocab = get_top_vocabulary(journals, chisquares,topk =50, threshold=0.0)\n","print(len(vocab))\n","train_title, valid_title, test_title = tf_idf(train,valid,test,\"title\",vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7650\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qSIhu_VLE7Z4","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589878023625,"user_tz":-420,"elapsed":8822,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"7455f51a-e469-48a0-ef24-da2e01f7fafb"},"source":["import pickle\n","with open(\"springer_keywords_chisquares.pickle\", \"rb\") as infile:\n","    chisquares = pickle.load(infile)\n","\n","vocab = get_top_vocabulary(journals, chisquares,topk =50, threshold=0.0)\n","print(len(vocab))\n","train_keywords, valid_keywords, test_keywords = tf_idf(train,valid,test,\"keywords\",vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7593\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1rVMg2ulzkIQ"},"source":["# S2RSCS"]},{"cell_type":"code","metadata":{"id":"XOVuZVcXE7Z7","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1589872322422,"user_tz":-420,"elapsed":1034,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"751e99bb-5d7b-422c-e75c-81c648570ca5"},"source":["\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","\n","class ModelCheckpoint(tf.keras.callbacks.Callback):\n","\n","    def __init__(self, max_no_improvements=50):\n","        super(ModelCheckpoint, self).__init__()\n","        self.best_val_acc = 0.0\n","        self.best_weights = None\n","        self.max_no_improvements = max_no_improvements\n","        self.n_no_improvements = 0\n","\n","    def on_epoch_end(self, epoch, logs):\n","        val_acc = logs[\"val_acc\"]\n","        if self.best_weights is None or val_acc >= self.best_val_acc:\n","            self.best_weights = self.model.get_weights()\n","            self.best_val_acc = val_acc\n","            self.n_no_improvements = 0\n","        else:\n","            self.n_no_improvements += 1\n","            if self.n_no_improvements > self.max_no_improvements:\n","                self.model.stop_training = True\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","\n","\n","inputs = Input(shape=(train_abstract.shape[1], ))\n","xx = Dense(units=300, activation='relu',\n","           kernel_regularizer=l2(0.0001))(inputs)\n","xx = Dropout(0.5)(xx)\n","softmax = Dense(units=len(journals), activation='softmax')(xx)\n","\n","model = Model(inputs=inputs, outputs=softmax)\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 7534)]            0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 300)               2260500   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 300)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 178)               53578     \n","=================================================================\n","Total params: 2,314,078\n","Trainable params: 2,314,078\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Edz-sSY-E7Z9"},"source":["model.fit(train_abstract, y_train, epochs=1000, batch_size=128, validation_data = (valid_abstract, y_valid), callbacks= [ModelCheckpoint()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9GQEmeFrWPD"},"source":["probabilities = model.predict(valid_abstract)\n","\n","print(np.mean(np.repeat(y_valid, 1).reshape(-1,1) == np.argsort(probabilities, axis=-1)[:,:-2:-1])*1)\n","print(np.mean(np.repeat(y_valid, 3).reshape(-1,3) == np.argsort(probabilities, axis=-1)[:,:-4:-1])*3)\n","print(np.mean(np.repeat(y_valid, 5).reshape(-1,5) == np.argsort(probabilities, axis=-1)[:,:-6:-1])*5)\n","print(np.mean(np.repeat(y_valid, 10).reshape(-1,10) == np.argsort(probabilities, axis=-1)[:,:-11:-1])*10)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WYdK-LpM-qT"},"source":["from sklearn.neural_network import MLPClassifier\n","clf = MLPClassifier(early_stopping=True, validation_fraction=0.1,hidden_layer_sizes=(300,))\n","clf.fit(train_abstract,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tBwNsh9MNIax"},"source":["probabilities = clf.predict_proba(valid_abstract)\n","\n","print(np.mean(np.repeat(y_valid, 1).reshape(-1,1) == np.argsort(probabilities, axis=-1)[:,:-2:-1])*1)\n","print(np.mean(np.repeat(y_valid, 3).reshape(-1,3) == np.argsort(probabilities, axis=-1)[:,:-4:-1])*3)\n","print(np.mean(np.repeat(y_valid, 5).reshape(-1,5) == np.argsort(probabilities, axis=-1)[:,:-6:-1])*5)\n","print(np.mean(np.repeat(y_valid, 10).reshape(-1,10) == np.argsort(probabilities, axis=-1)[:,:-11:-1])*10)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aynr04e2z4f-"},"source":["# MoE"]},{"cell_type":"code","metadata":{"id":"8at7p9Js3W5T"},"source":["springer_labels = [\n","  'environmental modeling & assessment',\n","  'korean journal of computational and applied mathematics',\n","  'annali dell’università di ferrara',\n","  'differential equations and dynamical systems',\n","  'journal of applied and industrial mathematics',\n","  'set-valued analysis',\n","  'geometric & functional analysis gafa',\n","  'computational particle mechanics',\n","  'information systems frontiers',\n","  'computational and applied mathematics',\n","  'semigroup forum',\n","  'moscow university mathematics bulletin',\n","  'computational mechanics',\n","  'educational studies in mathematics',\n","  'applied mathematics',\n","  'memetic computing',\n","  'nonrenewable resources',\n","  'telecommunication systems',\n","  'annals of operations research',\n","  'journal of automated reasoning',\n","  'quarterly journal of the belgian, french and italian operations research societies',\n","  'integral equations and operator theory',\n","  'computing and visualization in science',\n","  'allgemeines statistisches archiv',\n","  'logica universalis',\n","  'proceedings of the steklov institute of mathematics',\n","  'acta applicandae mathematica',\n","  'fuzzy optimization and decision making',\n","  'evolutionary intelligence',\n","  'journal of geometry',\n","  'rendiconti del circolo matematico di palermo',\n","  'opsearch',\n","  'mathematics in computer science',\n","  'automation and remote control',\n","  'top',\n","  'bulletin of the malaysian mathematical sciences society',\n","  'mathematical models and computer simulations',\n","  'journal of optimization theory and applications',\n","  'minds and machines',\n","  'mathematics of control, signals and systems',\n","  'journal of soviet mathematics',\n","  'queueing systems',\n","  'racsam - revista de la real academia de ciencias exactas, fisicas y naturales. serie a. matematicas',\n","  'calcolo',\n","  'potential analysis',\n","  'doklady mathematics',\n","  'inventiones mathematicae',\n","  \"publications mathématiques de l'institut des hautes études scientifiques\",\n","  'operations-research-spektrum',\n","  'nonlinear differential equations and applications nodea',\n","  'p-adic numbers, ultrametric analysis, and applications',\n","  'sema journal',\n","  'journal of fourier analysis and applications',\n","  'arabian journal of mathematics',\n","  'analysis and mathematical physics',\n","  'mediterranean journal of mathematics',\n","  'computational optimization and applications',\n","  'siberian advances in mathematics',\n","  'journal of algebraic combinatorics',\n","  'the journal of the astronautical sciences',\n","  'general relativity and gravitation',\n","  'environmentalist',\n","  'foundations of computational mathematics',\n","  'revista matemática complutense',\n","  'science in china series a: mathematics',\n","  'annals of combinatorics',\n","  'ricerche di matematica',\n","  'numerical algorithms',\n","  'structural optimization',\n","  'journal of theoretical probability',\n","  'algebra and logic',\n","  'algebra universalis',\n","  'theoretical and mathematical physics',\n","  'russian mathematics',\n","  'communications in mathematical physics',\n","  'mathematical programming computation',\n","  'journal of global optimization',\n","  'annali di matematica pura ed applicata',\n","  'letters in mathematical physics',\n","  'jahresbericht der deutschen mathematiker-vereinigung',\n","  'statistical inference for stochastic processes',\n","  'zdm',\n","  'calculus of variations and partial differential equations',\n","  'journal of control theory and applications',\n","  'statistische hefte',\n","  'vietnam journal of mathematics',\n","  'mathematical programming',\n","  'energy systems',\n","  'boletín de la sociedad matemática mexicana',\n","  'journal of evolution equations',\n","  'journal of nonlinear science',\n","  'international journal of applied and computational mathematics',\n","  'lobachevskii journal of mathematics',\n","  'mathematics and financial economics',\n","  'complex analysis and operator theory',\n","  'computational statistics',\n","  'metrika',\n","  'computational complexity',\n","  'unternehmensforschung',\n","  'annales des télécommunications',\n","  'foundations of science',\n","  'experimental economics',\n","  'optimization and engineering',\n","  'operational research',\n","  'computational geosciences',\n","  'journal of fixed point theory and applications',\n","  'discrete event dynamic systems',\n","  'advances in applied clifford algebras',\n","  'collectanea mathematica',\n","  'computational methods and function theory',\n","  'international journal of game theory',\n","  'rendiconti del seminario matematico e fisico di milano',\n","  'combinatorica',\n","  'computational mathematics and mathematical physics',\n","  'acta mathematica sinica',\n","  'annals of finance',\n","  'journal of combinatorial optimization',\n","  'neural computing & applications',\n","  'japan journal of applied mathematics',\n","  'mathematical sciences',\n","  'dynamic games and applications',\n","  'cryptography and communications',\n","  'constraints',\n","  'advances in computational mathematics',\n","  'analysis mathematica',\n","  'applied mathematics and mechanics',\n","  'engineering with computers',\n","  'beiträge zur algebra und geometrie / contributions to algebra and geometry',\n","  'journal of engineering mathematics',\n","  'journal d’analyse mathématique',\n","  'european actuarial journal',\n","  'journal of scheduling',\n","  'annals of mathematics and artificial intelligence',\n","  'mathematische zeitschrift',\n","  'international journal of fuzzy systems',\n","  'journal of scientific computing',\n","  'zeitschrift für nationalökonomie',\n","  'modeling earth systems and environment',\n","  'numerische mathematik',\n","  'journal of dynamical and control systems',\n","  'theoretical and computational fluid dynamics',\n","  'interdisciplinary sciences: computational life sciences',\n","  'acta mathematica vietnamica',\n","  'journal of statistical theory and practice',\n","  'soviet applied mechanics',\n","  'discrete & computational geometry',\n","  'the ramanujan journal',\n","  'positivity',\n","  'mathematische annalen',\n","  'qualitative theory of dynamical systems',\n","  'regular and chaotic dynamics',\n","  'journal of cryptology',\n","  'israel journal of mathematics',\n","  'journal of mathematical biology',\n","  'social network analysis and mining',\n","  'results in mathematics',\n","  'journal of heuristics',\n","  'annales henri poincaré',\n","  'journal of systems science and complexity',\n","  'multibody system dynamics',\n","  'soft computing',\n","  'mathematical physics, analysis and geometry',\n","  'journal of mathematical imaging and vision',\n","  'selecta mathematica',\n","  'kn - journal of cartography and geographic information',\n","  'journal of dynamics and differential equations',\n","  'periodica mathematica hungarica',\n","  'computational management science',\n","  'journal of the operations research society of china',\n","  \"bollettino dell'unione matematica italiana\",\n","  'siberian mathematical journal',\n","  'numerical analysis and applications',\n","  'the journal of geometric analysis',\n","  'journal of quantitative economics',\n","  'computational mathematics and modeling',\n","  'mathematical notes of the academy of sciences of the ussr',\n","  'european journal of mathematics',\n","  'transformation groups',\n","  'cybernetics',\n","  'quantum information processing',\n","  'monatshefte für mathematik und physik',\n","  'afrika matematika',\n","  'archiv für mathematische logik und grundlagenforschung',\n","  'optimization letters',\n","  'economic theory bulletin',\n","  'constructive approximation',\n","  'functional analysis and its applications',\n","  'theory in biosciences',\n","  'journal of pseudo-differential operators and applications',\n","  'stochastic hydrology and hydraulics',\n","  'moscow university computational mathematics and cybernetics',\n","  'theory and decision',\n","  'vestnik st. petersburg university: mathematics',\n","  'bit numerical mathematics',\n","  'applied mathematics and optimization',\n","  'celestial mechanics']\n","\n","journal_to_idx = {journal:ii for ii, journal in enumerate(springer_labels)}\n","\n","y_train = [journal_to_idx[item[\"journal\"]] for item in train]\n","y_valid = [journal_to_idx[item[\"journal\"]] for item in valid]\n","y_test = [journal_to_idx[item[\"journal\"]] for item in test]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nEUVjrQc3zFD"},"source":["import numpy as np\n","\n","def get_accuracy(y_true, y_pred):\n","    top1 = np.mean(np.repeat(y_true, 1).reshape(-1,1) == np.argsort(y_pred, axis=-1)[:,:-2:-1])*1\n","    top3 = np.mean(np.repeat(y_true, 3).reshape(-1,3) == np.argsort(y_pred, axis=-1)[:,:-4:-1])*3\n","    top5 = np.mean(np.repeat(y_true, 5).reshape(-1,5) == np.argsort(y_pred, axis=-1)[:,:-6:-1])*5\n","    top10 = np.mean(np.repeat(y_true, 10).reshape(-1,10) == np.argsort(y_pred, axis=-1)[:,:-11:-1])*10\n","    return [top1, top3, top5, top10]\n","def softmax_func(logits):\n","    return np.exp(logits) / np.sum(np.exp(logits), axis=1).reshape(-1,1)\n","\n","\n","valid_softmaxes = []\n","test_softmaxes = []\n","features = \"abstract\"\n","for model in ['scibert', 'xlnet', 'electra']:\n","    softmax = np.load(\"softmaxes/springer-{}-{}-valid.npy\".format(model, features)).astype(float)\n","    if model in ['xlnet', 'electra']: softmax = softmax_func(softmax)\n","    valid_softmaxes.append(softmax)\n","\n","    softmax = np.load(\"softmaxes/springer-{}-{}-test.npy\".format(model, features)).astype(float)\n","    if model in ['xlnet', 'electra']: softmax = softmax_func(softmax)\n","    test_softmaxes.append(softmax)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNZboJ6hz3et","colab":{"base_uri":"https://localhost:8080/","height":578},"executionInfo":{"status":"ok","timestamp":1589883770640,"user_tz":-420,"elapsed":1276,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"a8e8e822-04c0-4780-982b-9b768507dbd9"},"source":["\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Dropout, Lambda, Concatenate, Reshape, Multiply\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","\n","\n","\n","\n","input_tfidf = Input(shape=(train_abstract.shape[1], ))\n","\n","input_softmax_1 = Input(shape=(196, ))\n","input_softmax_2 = Input(shape=(196, ))\n","input_softmax_3 = Input(shape=(196, ))\n","\n","ss = Concatenate()([Reshape((196,1))(input_softmax_1), \n","                    Reshape((196,1))(input_softmax_2), \n","                    Reshape((196,1))(input_softmax_3)])\n","\n","# xx = Dense(units=300, activation='relu',\n","#            kernel_regularizer=l2(0.01))(input_tfidf)\n","# xx = Dropout(0.5)(xx)\n","\n","weights = Dense(units=3, activation='softmax')(input_tfidf)\n","\n","softmax = Multiply()([ss,weights])\n","softmax = Lambda(lambda x: tf.reduce_sum(x, axis=-1))(softmax)\n","\n","model = Model(inputs=[input_tfidf, input_softmax_1, input_softmax_2, input_softmax_3], outputs=softmax)\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_14\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_58 (InputLayer)           [(None, 196)]        0                                            \n","__________________________________________________________________________________________________\n","input_59 (InputLayer)           [(None, 196)]        0                                            \n","__________________________________________________________________________________________________\n","input_60 (InputLayer)           [(None, 196)]        0                                            \n","__________________________________________________________________________________________________\n","reshape_42 (Reshape)            (None, 196, 1)       0           input_58[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_43 (Reshape)            (None, 196, 1)       0           input_59[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_44 (Reshape)            (None, 196, 1)       0           input_60[0][0]                   \n","__________________________________________________________________________________________________\n","input_57 (InputLayer)           [(None, 7534)]       0                                            \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 196, 3)       0           reshape_42[0][0]                 \n","                                                                 reshape_43[0][0]                 \n","                                                                 reshape_44[0][0]                 \n","__________________________________________________________________________________________________\n","dense_23 (Dense)                (None, 3)            22605       input_57[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_14 (Multiply)          (None, 196, 3)       0           concatenate_14[0][0]             \n","                                                                 dense_23[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 196)          0           multiply_14[0][0]                \n","==================================================================================================\n","Total params: 22,605\n","Trainable params: 22,605\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BZrZKGVWTtNl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t040zFse4vXr"},"source":["from sklearn.model_selection import train_test_split\n","valid_train_abstract, valid_valid_abstract, y_valid_train, y_valid_valid, \\\n","    valid_train_softmax_1, valid_valid_softmax_1, \\\n","    valid_train_softmax_2, valid_valid_softmax_2, \\\n","    valid_train_softmax_3, valid_valid_softmax_3 = train_test_split(valid_abstract, y_valid, valid_softmaxes[0], valid_softmaxes[1], valid_softmaxes[2], test_size=0.2, stratify=y_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jg8217bO2MRN","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589883801953,"user_tz":-420,"elapsed":31875,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"be75d111-dd14-489e-cbdf-617bce330fb0"},"source":["class ModelCheckpoint(tf.keras.callbacks.Callback):\n","\n","    def __init__(self, max_no_improvements=50):\n","        super(ModelCheckpoint, self).__init__()\n","        self.best_val_acc = 0.0\n","        self.best_weights = None\n","        self.max_no_improvements = max_no_improvements\n","        self.n_no_improvements = 0\n","\n","    def on_epoch_end(self, epoch, logs):\n","        val_acc = logs[\"val_acc\"]\n","        if self.best_weights is None or val_acc >= self.best_val_acc:\n","            self.best_weights = self.model.get_weights()\n","            self.best_val_acc = val_acc\n","            self.n_no_improvements = 0\n","        else:\n","            self.n_no_improvements += 1\n","            if self.n_no_improvements > self.max_no_improvements:\n","                self.model.stop_training = True\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","model.fit([valid_train_abstract, valid_train_softmax_1, valid_train_softmax_2, valid_train_softmax_3 ], \n","          y_valid_train, \n","          epochs=1000, \n","          batch_size=128, \n","          callbacks= [ModelCheckpoint()],\n","          validation_data=([valid_valid_abstract, valid_valid_softmax_1, valid_valid_softmax_2, valid_valid_softmax_3 ], y_valid_valid))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 11956 samples, validate on 2989 samples\n","Epoch 1/1000\n","11956/11956 [==============================] - 1s 84us/sample - loss: 2.3161 - acc: 0.4386 - val_loss: 2.3322 - val_acc: 0.4389\n","Epoch 2/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.3110 - acc: 0.4386 - val_loss: 2.3311 - val_acc: 0.4383\n","Epoch 3/1000\n","11956/11956 [==============================] - 1s 46us/sample - loss: 2.3078 - acc: 0.4390 - val_loss: 2.3309 - val_acc: 0.4383\n","Epoch 4/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.3052 - acc: 0.4404 - val_loss: 2.3309 - val_acc: 0.4386\n","Epoch 5/1000\n","11956/11956 [==============================] - 1s 49us/sample - loss: 2.3028 - acc: 0.4408 - val_loss: 2.3310 - val_acc: 0.4383\n","Epoch 6/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.3005 - acc: 0.4418 - val_loss: 2.3312 - val_acc: 0.4369\n","Epoch 7/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2983 - acc: 0.4423 - val_loss: 2.3313 - val_acc: 0.4373\n","Epoch 8/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2961 - acc: 0.4431 - val_loss: 2.3315 - val_acc: 0.4369\n","Epoch 9/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2941 - acc: 0.4440 - val_loss: 2.3317 - val_acc: 0.4369\n","Epoch 10/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2920 - acc: 0.4443 - val_loss: 2.3319 - val_acc: 0.4373\n","Epoch 11/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2900 - acc: 0.4452 - val_loss: 2.3321 - val_acc: 0.4366\n","Epoch 12/1000\n","11956/11956 [==============================] - 1s 49us/sample - loss: 2.2880 - acc: 0.4461 - val_loss: 2.3323 - val_acc: 0.4373\n","Epoch 13/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2860 - acc: 0.4462 - val_loss: 2.3326 - val_acc: 0.4373\n","Epoch 14/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2841 - acc: 0.4471 - val_loss: 2.3328 - val_acc: 0.4366\n","Epoch 15/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2823 - acc: 0.4476 - val_loss: 2.3331 - val_acc: 0.4366\n","Epoch 16/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2804 - acc: 0.4480 - val_loss: 2.3333 - val_acc: 0.4363\n","Epoch 17/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2786 - acc: 0.4490 - val_loss: 2.3337 - val_acc: 0.4359\n","Epoch 18/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2769 - acc: 0.4498 - val_loss: 2.3339 - val_acc: 0.4369\n","Epoch 19/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2751 - acc: 0.4502 - val_loss: 2.3342 - val_acc: 0.4366\n","Epoch 20/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2735 - acc: 0.4507 - val_loss: 2.3345 - val_acc: 0.4369\n","Epoch 21/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2718 - acc: 0.4516 - val_loss: 2.3349 - val_acc: 0.4359\n","Epoch 22/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2702 - acc: 0.4522 - val_loss: 2.3352 - val_acc: 0.4369\n","Epoch 23/1000\n","11956/11956 [==============================] - 1s 49us/sample - loss: 2.2686 - acc: 0.4524 - val_loss: 2.3356 - val_acc: 0.4369\n","Epoch 24/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2670 - acc: 0.4530 - val_loss: 2.3359 - val_acc: 0.4373\n","Epoch 25/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2655 - acc: 0.4532 - val_loss: 2.3362 - val_acc: 0.4366\n","Epoch 26/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2639 - acc: 0.4539 - val_loss: 2.3366 - val_acc: 0.4373\n","Epoch 27/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2624 - acc: 0.4542 - val_loss: 2.3370 - val_acc: 0.4376\n","Epoch 28/1000\n","11956/11956 [==============================] - 1s 46us/sample - loss: 2.2610 - acc: 0.4548 - val_loss: 2.3374 - val_acc: 0.4383\n","Epoch 29/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2595 - acc: 0.4554 - val_loss: 2.3377 - val_acc: 0.4379\n","Epoch 30/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2581 - acc: 0.4559 - val_loss: 2.3382 - val_acc: 0.4373\n","Epoch 31/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2567 - acc: 0.4563 - val_loss: 2.3385 - val_acc: 0.4366\n","Epoch 32/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2554 - acc: 0.4568 - val_loss: 2.3390 - val_acc: 0.4359\n","Epoch 33/1000\n","11956/11956 [==============================] - 1s 49us/sample - loss: 2.2540 - acc: 0.4572 - val_loss: 2.3394 - val_acc: 0.4353\n","Epoch 34/1000\n","11956/11956 [==============================] - 1s 45us/sample - loss: 2.2527 - acc: 0.4576 - val_loss: 2.3399 - val_acc: 0.4346\n","Epoch 35/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2514 - acc: 0.4578 - val_loss: 2.3403 - val_acc: 0.4349\n","Epoch 36/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2501 - acc: 0.4583 - val_loss: 2.3406 - val_acc: 0.4343\n","Epoch 37/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2489 - acc: 0.4588 - val_loss: 2.3411 - val_acc: 0.4336\n","Epoch 38/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2476 - acc: 0.4593 - val_loss: 2.3415 - val_acc: 0.4336\n","Epoch 39/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2464 - acc: 0.4595 - val_loss: 2.3419 - val_acc: 0.4323\n","Epoch 40/1000\n","11956/11956 [==============================] - 1s 46us/sample - loss: 2.2452 - acc: 0.4596 - val_loss: 2.3424 - val_acc: 0.4319\n","Epoch 41/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2440 - acc: 0.4600 - val_loss: 2.3428 - val_acc: 0.4323\n","Epoch 42/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2428 - acc: 0.4604 - val_loss: 2.3432 - val_acc: 0.4323\n","Epoch 43/1000\n","11956/11956 [==============================] - 1s 46us/sample - loss: 2.2417 - acc: 0.4604 - val_loss: 2.3436 - val_acc: 0.4309\n","Epoch 44/1000\n","11956/11956 [==============================] - 1s 46us/sample - loss: 2.2406 - acc: 0.4604 - val_loss: 2.3441 - val_acc: 0.4312\n","Epoch 45/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2395 - acc: 0.4614 - val_loss: 2.3445 - val_acc: 0.4312\n","Epoch 46/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2384 - acc: 0.4619 - val_loss: 2.3449 - val_acc: 0.4306\n","Epoch 47/1000\n","11956/11956 [==============================] - 1s 46us/sample - loss: 2.2373 - acc: 0.4621 - val_loss: 2.3454 - val_acc: 0.4309\n","Epoch 48/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2362 - acc: 0.4625 - val_loss: 2.3458 - val_acc: 0.4306\n","Epoch 49/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2352 - acc: 0.4626 - val_loss: 2.3463 - val_acc: 0.4309\n","Epoch 50/1000\n","11956/11956 [==============================] - 1s 47us/sample - loss: 2.2341 - acc: 0.4628 - val_loss: 2.3468 - val_acc: 0.4309\n","Epoch 51/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2331 - acc: 0.4634 - val_loss: 2.3472 - val_acc: 0.4309\n","Epoch 52/1000\n","11956/11956 [==============================] - 1s 48us/sample - loss: 2.2321 - acc: 0.4640 - val_loss: 2.3476 - val_acc: 0.4302\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f6518bc3a20>"]},"metadata":{"tags":[]},"execution_count":165}]},{"cell_type":"code","metadata":{"id":"b21FnuTB2Wqs","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589883803386,"user_tz":-420,"elapsed":33084,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"cbc5001b-f275-47b5-d789-df5db4181668"},"source":["get_accuracy(y_valid_train, model.predict([valid_train_abstract, valid_train_softmax_1, valid_train_softmax_2, valid_train_softmax_3 ]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.4386918701906992, 0.6670291067246571, 0.7542656406825026, 0.857728337236534]"]},"metadata":{"tags":[]},"execution_count":166}]},{"cell_type":"code","metadata":{"id":"EuHTpPtmU3BC","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589883803389,"user_tz":-420,"elapsed":32818,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"5b6b07cb-c4f3-48ed-a947-cbf40908076b"},"source":["get_accuracy(y_valid_valid, model.predict([valid_valid_abstract, valid_valid_softmax_1, valid_valid_softmax_2, valid_valid_softmax_3 ]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.4389427902308464, 0.6651053864168618, 0.75209100033456, 0.8568082970893276]"]},"metadata":{"tags":[]},"execution_count":167}]},{"cell_type":"code","metadata":{"id":"kl224sNyz3iQ","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1589883804993,"user_tz":-420,"elapsed":33714,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"b2ce6a49-8edd-4edb-e490-e37d17362d1e"},"source":["get_accuracy(y_test, model.predict([test_abstract] + test_softmaxes))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.4386082301773168,\n"," 0.6580127132820341,\n"," 0.7473402475744396,\n"," 0.8525928404148544]"]},"metadata":{"tags":[]},"execution_count":168}]},{"cell_type":"code","metadata":{"id":"SsdLk4bqz3lT","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589883805327,"user_tz":-420,"elapsed":33694,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"38b82ea1-4272-487a-b78f-b1116a90158e"},"source":["get_accuracy(y_test, sum(test_softmaxes))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.4382736701237872, 0.65807962529274, 0.7472733355637338, 0.8521244563399131]"]},"metadata":{"tags":[]},"execution_count":169}]},{"cell_type":"code","metadata":{"id":"KjijJdgqz3nw"},"source":["get_accuracy(y_valid, sum(valid_softmaxes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivmiSbNXz3qs","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589880958571,"user_tz":-420,"elapsed":744,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"6e46d10f-e7c1-4ea0-a098-c22e237635ac"},"source":["np.argmax(valid_softmaxes[0], axis=-1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([125, 141,  68, ..., 179,  54, 160])"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"bRZZblyuz3t9","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1589881808312,"user_tz":-420,"elapsed":4893,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}},"outputId":"98e353a0-6b6c-44da-d9a3-9a4d1cf668a6"},"source":["np.sum(model.predict([valid_train_abstract, valid_train_softmax_1, valid_train_softmax_2, valid_train_softmax_3 ]), axis=-1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.99999994, 1.        , 1.        , ..., 0.9999999 , 1.        ,\n","       1.        ], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":74}]}]}