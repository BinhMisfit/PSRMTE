{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"feature.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qaPIc9w3E7Zt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"outputId":"161d8fc1-876d-462c-edf6-b28316b62f92","executionInfo":{"status":"ok","timestamp":1588691852274,"user_tz":-420,"elapsed":58515,"user":{"displayName":"Đinh Viết Cường","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMF2IqwIQmt7pmaCxJEwjk36PmvnhHmWl4Op7_=s64","userId":"04868867703989860835"}}},"source":["%tensorflow_version 1.x\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 144568 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.21-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.21-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.21-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RXCO_eKHagni","colab_type":"code","colab":{}},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/tfidf-paper/\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vc6UYSQSZ-Jb","colab_type":"code","colab":{}},"source":["\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","# extracting features\n","#df is data\n","#name is one of Abstract, Title, Keywords\n","def chi(df,name): \n","    \n","    Dic=[]         #Dictionary contains chi-value of every word belong to certain category \n","    caTegory=[]\n","    for i in df.category:\n","      if i not in caTegory:\n","        caTegory.append(i)\n","    for i in caTegory:\n","      #print(i)\n","      doc=np.array(df[name][df.category==i])\n","      doc1=np.array(df[name][df.category!=i])\n","      vect =  CountVectorizer(binary=True,lowercase = True,ngram_range=(1,1))             \n","      X_dtm = vect.fit_transform(doc)\n","      vect1= CountVectorizer(binary=True,lowercase = True,ngram_range=(1,1),vocabulary=vect.get_feature_names())  \n","      \n","      A = np.sum(X_dtm.toarray(),axis=0)\n","      B=vect1.fit_transform(doc1)\n","      B = np.sum(B.toarray(),axis=0)\n","      C=len(train.category[train.category==i])*np.ones([1,len(A)])\n","      D=len(train.category[train.category!=i])*np.ones([1,len(B)])\n","      C=C[0]-A\n","      D=D[0]-B\n","      result=((A+B+C+D)*(A*D-B*C)**2)/((A+C)*(B+D)*(A+B)*(C+D))\n","     \n","      Dic.append(dict(zip(vect.get_feature_names(),result)))\n","      del doc,doc1,vect1,vect,X_dtm,A,B,C,D,result\n","    return Dic\n","\n","#save and load\n","import pickle\n","def save_obj(obj, name ):\n","    with open( name +'.pkl', 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","def load_obj(name ):\n","    with open( name + '.pkl', 'rb') as f:\n","        return pickle.load(f)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6N8g7ncE7Zx","colab_type":"code","colab":{}},"source":["import pandas as pd\n","path=\"/opt/dac_research/Son/old_method/\"\n","train=pd.read_csv(path+\"Train.csv\")\n","valid=pd.read_csv(path+\"Valid.csv\")\n","test=pd.read_csv(path+\"Test.csv\")\n","\n","chi_abstract=chi(train,\"abstract\")\n","chi_title=chi(train,\"title\")\n","chi_key=chi(train,\"keywords\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5EQ2pCUE7Z0","colab_type":"code","colab":{}},"source":["def get_feature(df1,Dic):\n","    caTegory=[]\n","    for i in df1.category:\n","      if i not in caTegory:\n","        caTegory.append(i)\n","    \n","    Word=[]\n","    for i in range(0,len(caTegory)):\n","      j=0\n","    #get 50 top words \n","      for dic,val in {k: v for k, v in sorted(Dic[i].items(), key=lambda item: item[1],reverse=True)}.items():\n","        j=j+1\n","        Word.append(dic)\n","        if j >=50:\n","          break\n","    Word=__builtins__.list(set(Word)) \n","    return Word\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2eKR43zxE7Z2","colab_type":"code","colab":{}},"source":["abstract=get_feature(train,chi_abstract)\n","title=get_feature(train,chi_title)\n","key=get_feature(train,chi_key)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSIhu_VLE7Z4","colab_type":"code","colab":{}},"source":["caTegory=[]\n","for i in train.category:\n","    if i not in caTegory:\n","        caTegory.append(i)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOVuZVcXE7Z7","colab_type":"code","colab":{}},"source":["def tf_idf(train,test,valid,name,chi_name): #name is a string\n","#train\n","    tfidf = TfidfVectorizer(vocabulary=chi_name, ngram_range=(1,1))\n","    tfidf.fit_transform(__builtins__.list(train[name]))\n","    Vector_Train=tfidf.transform(__builtins__.list(train[name]))\n","    Vector_train=Vector_Train.toarray()\n","\n","#test\n","    Vector_Test=tfidf.transform(__builtins__.list(test[name]))\n","    Vector_test=Vector_Test.toarray()\n","\n","\n","#valid\n","    Vector_Valid=tfidf.transform(__builtins__.list(valid[name]))\n","    Vector_valid=Vector_Valid.toarray()\n","    return Vector_train, Vector_test, Vector_valid"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Edz-sSY-E7Z9","colab_type":"code","colab":{}},"source":["Vector_abstract_train,Vector_abstract_test,Vector_abstract_valid=tf_idf(train,test,valid,\"abstract\",abstract)\n","\n","Vector_title_train,Vector_title_test,Vector_title_valid=tf_idf(train,test,valid,\"title\",title)\n","\n","Vector_keywords_train,Vector_keywords_test,Vector_keywords_valid=tf_idf(train,test,valid,\"keywords\",key)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2metkRJE7aB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}