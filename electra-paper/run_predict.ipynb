{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_predict.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"shOngU3Foet_"},"source":["# Load Library"]},{"cell_type":"code","metadata":{"id":"v0bDcFVC_CgT"},"source":["%tensorflow_version 1.x\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwR0rq7m_FX6"},"source":["%tensorflow_version 1.x\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/electra-paper/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NxMd-Jzz_QFA"},"source":["import datetime\n","import json\n","import os\n","import pprint\n","import random\n","import string\n","import sys\n","import tensorflow as tf\n","\n","assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n","TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","print('TPU address is', TPU_ADDRESS)\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","with tf.Session(TPU_ADDRESS) as session:\n","  print('TPU devices:')\n","  pprint.pprint(session.list_devices())\n","\n","  # Upload credentials to TPU.\n","  with open('/content/adc.json', 'r') as f:\n","    auth_info = json.load(f)\n","  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","  # Now credentials are set for all future sessions on this TPU."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LmgxMcdnohOF"},"source":["# Main"]},{"cell_type":"markdown","metadata":{"id":"ldymL3aoolFS"},"source":["## CS"]},{"cell_type":"code","metadata":{"id":"obU_QYTpMrVk"},"source":["FEATURES = [\"title\", \"keywords\", \"abstract\"]\n","MODEL = \"model.ckpt-690\" if \"keywords\" in FEATURES else \"model.ckpt-740\"\n","if \"abstract\" in FEATURES:\n","    max_seq_length = 512\n","elif len(FEATURES) == 2:\n","    max_seq_length = 256\n","else:\n","    max_seq_length = 128\n","\n","hparams = {\n","    \"task_names\": [\"cs-paper\"],\n","    \"features\": FEATURES,\n","    \"model_dir\": \"gs://paper/electra-cspaper-{}/\".format(\"+\".join(FEATURES)), \n","    \"preprocessed_data_dir\": \"gs://paper/electra-cspaper-{}/\".format(\"+\".join(FEATURES)),\n","\n","    \"model_size\": \"base\",\n","    \"max_seq_length\": max_seq_length,\n","    \"vocab_file\": \"gs://bert-eng/electra_base/vocab.txt\",\n","    \"init_checkpoint\": \"gs://bert-eng/electra_base/electra_base\",\n","    \"do_lower_case\": True, \n","    \"keep_all_models\": True,\n","\n","    \"do_train\": True,\n","    \"train_batch_size\": 128,\n","    \"num_train_epochs\": 10.0,\n","    \"save_checkpoints_steps\": 1000, \n","    \"iterations_per_loop\": 1000,\n","    \"use_tfrecords_if_existing\": False,\n","\n","    \"do_eval\": True,\n","    \"do_test\": True,\n","    \"eval_batch_size\": 128,\n","    \"predict_batch_size\": 128,\n","    \"results_txt\": \"gs://paper/electra-cspaper-{}/results.txt\".format(\"+\".join(FEATURES)),\n","    \"results_pkl\": \"gs://paper/electra-cspaper-{}/results.pkl\".format(\"+\".join(FEATURES)),\n","    \n","    \"use_tpu\": True,\n","    \"num_tpu_cores\": 8,\n","    \"tpu_name\": TPU_ADDRESS,\n","}\n","\n","hparams.update({\n","    \"do_train\": False,\n","    \"do_eval\": False,\n","    \"do_test\": False,\n","    \"do_predict\": True,\n","    \"predict_checkpoint_path\": \"gs://paper/electra-cspaper-{}/_1/{}\".format(\"+\".join(FEATURES), MODEL),\n","    \"predict_split\": \"train,dev\",\n","})\n","\n","\n","import json\n","with open(\"paper_config.json\", \"w\") as outfile:\n","    json.dump(hparams, outfile)\n","\n","!python3 run_finetuning.py \\\n","    --data-dir=cs-paper/ \\\n","    --model-name=test \\\n","    --hparams=paper_config.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cy9XvjKDMrZT"},"source":["with open(\"predict_dev.pickle\", \"rb\") as infile:\n","    import pickle\n","    predict = pickle.load(infile)\n","import numpy as np\n","probabilities = np.asarray([item['cs-paper_logits'] for item in predict  if item['task_id'] == 0])\n","\n","from finetune.classification.classification_tasks import cs_labels\n","journal_2_index = {journal: i for i, journal in enumerate(cs_labels)}\n","\n","import json\n","y_valid = []\n","for line in open(\"../data/cs-paper/valid.jsonl\"):\n","    line = json.loads(line)\n","    do_skip = False\n","    for feature in hparams['features']:\n","        if feature not in line or type(line[feature]) != str or \\\n","            len(line[feature]) < 1: do_skip = True\n","    if not do_skip:\n","        y_valid.append(journal_2_index[line['journal'].lower()])\n","y_valid = np.asarray(y_valid)\n","\n","\n","print(np.mean(np.repeat(y_valid, 1).reshape(-1,1) == np.argsort(probabilities, axis=-1)[:,:-2:-1])*1)\n","print(np.mean(np.repeat(y_valid, 3).reshape(-1,3) == np.argsort(probabilities, axis=-1)[:,:-4:-1])*3)\n","print(np.mean(np.repeat(y_valid, 5).reshape(-1,5) == np.argsort(probabilities, axis=-1)[:,:-6:-1])*5)\n","print(np.mean(np.repeat(y_valid, 10).reshape(-1,10) == np.argsort(probabilities, axis=-1)[:,:-11:-1])*10)\n","print()\n","\n","\n","\n","with open(\"predict_train.pickle\", \"rb\") as infile:\n","    import pickle\n","    predict = pickle.load(infile)\n","\n","import numpy as np\n","probabilities = np.asarray([item['cs-paper_logits'] for item in predict  if item['task_id'] == 0])\n","np.save(\"cs-electra-{}-train.npy\".format(\"+\".join(hparams['features'])), probabilities)\n","\n","import json\n","y_valid = []\n","for line in open(\"../data/cs-paper/train.jsonl\"):\n","    line = json.loads(line)\n","    if \"keywords\" in FEATURES and (\"keywords\" not in line or type(line['keywords']) != str or len(line['keywords']) < 1): continue\n","    y_valid.append(journal_2_index[line['journal'].lower()])\n","y_valid = np.asarray(y_valid)\n","\n","print(np.mean(np.repeat(y_valid, 1).reshape(-1,1) == np.argsort(probabilities, axis=-1)[:,:-2:-1])*1)\n","print(np.mean(np.repeat(y_valid, 3).reshape(-1,3) == np.argsort(probabilities, axis=-1)[:,:-4:-1])*3)\n","print(np.mean(np.repeat(y_valid, 5).reshape(-1,5) == np.argsort(probabilities, axis=-1)[:,:-6:-1])*5)\n","print(np.mean(np.repeat(y_valid, 10).reshape(-1,10) == np.argsort(probabilities, axis=-1)[:,:-11:-1])*10)\n","print()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O7dSWtWvomWw"},"source":["## Springer"]},{"cell_type":"code","metadata":{"id":"ISETghJKQ4H-"},"source":["hparams = {\n","    \"task_names\": [\"springer-paper\"],\n","    \"features\": [\"title\", \"keywords\", \"abstract\"],\n","    \"model_dir\": \"gs://paper/electra-springerpaper-title+keywords+abstract/\", \n","    \"preprocessed_data_dir\": \"gs://paper/electra-springerpaper-title+keywords+abstract/\",\n","\n","    \"model_size\": \"base\",\n","    \"max_seq_length\": 512,\n","    \"vocab_file\": \"gs://bert-eng/electra_base/vocab.txt\",\n","    \"init_checkpoint\": \"gs://bert-eng/electra_base/electra_base\",\n","    \"do_lower_case\": True, \n","    \"keep_all_models\": True,\n","\n","    \"do_train\": True,\n","    \"train_batch_size\": 128,\n","    \"num_train_epochs\": 10.0,\n","    \"save_checkpoints_steps\": 1000, \n","    \"iterations_per_loop\": 1000,\n","    \"use_tfrecords_if_existing\": False,\n","\n","    \"do_eval\": True,\n","    \"do_test\": True,\n","    \"eval_key\": \"top1_accuracy\",\n","    \"eval_batch_size\": 128,\n","    \"predict_batch_size\": 128,\n","    \"results_txt\": \"gs://paper/electra-springerpaper-title+keywords+abstract/results.txt\",\n","    \"results_pkl\": \"gs://paper/electra-springerpaper-title+keywords+abstract/results.pkl\",\n","    \n","    \"use_tpu\": True,\n","    \"num_tpu_cores\": 8,\n","    \"tpu_name\": TPU_ADDRESS,\n","}\n","\n","hparams.update({\n","    \"do_train\": False,\n","    \"do_eval\": False,\n","    \"do_test\": False,\n","    \"do_predict\": True,\n","    \"predict_checkpoint_path\": \"gs://paper/electra-springerpaper-title+keywords+abstract/_1/model.ckpt-15000\",\n","    \"predict_split\": \"train,dev\",\n","})\n","\n","\n","import json\n","with open(\"paper_config.json\", \"w\") as outfile:\n","    json.dump(hparams, outfile)\n","\n","!python3 run_finetuning.py \\\n","    --data-dir=springer-paper/ \\\n","    --model-name=test \\\n","    --hparams=paper_config.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4TzYHAevQ3_o"},"source":["with open(\"predict_dev.pickle\", \"rb\") as infile:\n","    import pickle\n","    predict = pickle.load(infile)\n","import numpy as np\n","probabilities = np.asarray([item['springer-paper_logits'] for item in predict  if item['task_id'] == 0])\n","\n","from finetune.classification.classification_tasks import springer_labels\n","journal_2_index = {journal: i for i, journal in enumerate(springer_labels)}\n","\n","import json\n","y_valid = []\n","for line in open(\"../data/springer-paper/valid.jsonl\"):\n","    line = json.loads(line)\n","    do_skip = False\n","    for feature in hparams['features']:\n","        if feature not in line or type(line[feature]) != str or \\\n","            len(line[feature]) < 1: do_skip = True\n","    if not do_skip:\n","        y_valid.append(journal_2_index[line['journal'].lower()])\n","y_valid = np.asarray(y_valid)\n","\n","\n","print(np.mean(np.repeat(y_valid, 1).reshape(-1,1) == np.argsort(probabilities, axis=-1)[:,:-2:-1])*1)\n","print(np.mean(np.repeat(y_valid, 3).reshape(-1,3) == np.argsort(probabilities, axis=-1)[:,:-4:-1])*3)\n","print(np.mean(np.repeat(y_valid, 5).reshape(-1,5) == np.argsort(probabilities, axis=-1)[:,:-6:-1])*5)\n","print(np.mean(np.repeat(y_valid, 10).reshape(-1,10) == np.argsort(probabilities, axis=-1)[:,:-11:-1])*10)\n","print()\n","\n","\n","\n","with open(\"predict_train.pickle\", \"rb\") as infile:\n","    import pickle\n","    predict = pickle.load(infile)\n","\n","import numpy as np\n","probabilities = np.asarray([item['springer-paper_logits'] for item in predict  if item['task_id'] == 0])\n","np.save(\"springer-electra-{}-train.npy\".format(\"+\".join(hparams['features'])), probabilities)\n","\n","import json\n","y_valid = []\n","for line in open(\"../data/springer-paper/train.jsonl\"):\n","    line = json.loads(line)\n","    y_valid.append(journal_2_index[line['journal'].lower()])\n","y_valid = np.asarray(y_valid)\n","\n","print(np.mean(np.repeat(y_valid, 1).reshape(-1,1) == np.argsort(probabilities, axis=-1)[:,:-2:-1])*1)\n","print(np.mean(np.repeat(y_valid, 3).reshape(-1,3) == np.argsort(probabilities, axis=-1)[:,:-4:-1])*3)\n","print(np.mean(np.repeat(y_valid, 5).reshape(-1,5) == np.argsort(probabilities, axis=-1)[:,:-6:-1])*5)\n","print(np.mean(np.repeat(y_valid, 10).reshape(-1,10) == np.argsort(probabilities, axis=-1)[:,:-11:-1])*10)\n","print()\n","\n"],"execution_count":null,"outputs":[]}]}