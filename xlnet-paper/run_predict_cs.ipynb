{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_predict_cs.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BfCN7LoRvoWO"},"source":["# Library"]},{"cell_type":"code","metadata":{"id":"oAWGj1NjLF7c"},"source":["%tensorflow_version 1.x\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hEel7De5LJ5C"},"source":["%tensorflow_version 1.x\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/xlnet-paper/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8t-m_SGLmRv"},"source":["import datetime\n","import json\n","import os\n","import pprint\n","import random\n","import string\n","import sys\n","import tensorflow as tf\n","\n","assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n","TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","print('TPU address is', TPU_ADDRESS)\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","with tf.Session(TPU_ADDRESS) as session:\n","  print('TPU devices:')\n","  pprint.pprint(session.list_devices())\n","\n","  # Upload credentials to TPU.\n","  with open('/content/adc.json', 'r') as f:\n","    auth_info = json.load(f)\n","  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","  # Now credentials are set for all future sessions on this TPU."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nit1gIPcNfPt"},"source":["!pip3 install sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWoYPS5FdBje"},"source":["FEATURES = [\"title\", \"keywords\", \"abstract\"] # [\"title\"]\n","DATA_DIR = \"../data/cs-paper/\"\n","OUTPUT_DIR = \"gs://paper/xlnet-base-cs-{}/\".format(\"+\".join(FEATURES))\n","PRETRAIN_MODEL_DIR = \"gs://bert-eng/xlnet-base-cased\"\n","\n","if \"abstract\" in FEATURES:\n","    max_seq_length = 512\n","elif len(FEATURES) == 2:\n","    max_seq_length = 256\n","else:\n","    max_seq_length = 128\n","fff = \",\".join(FEATURES)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K5XWol0QvrC6"},"source":["# Main code"]},{"cell_type":"code","metadata":{"id":"FjyYE8jkvNg8"},"source":["!python3 run_classifier_cs.py \\\n","  --features=$fff \\\n","  --overwrite_data=True \\\n","  --eval_split=dev \\\n","  --use_tpu=True \\\n","  --tpu=$TPU_ADDRESS \\\n","  --do_train=False \\\n","  --do_eval=False \\\n","  --do_predict=True \\\n","  --data_dir=$DATA_DIR \\\n","  --predict_ckpt=$OUTPUT_DIR/model.ckpt \\\n","  --output_dir=$OUTPUT_DIR \\\n","  --model_dir=$OUTPUT_DIR \\\n","  --predict_dir=$OUTPUT_DIR \\\n","  --uncased=True \\\n","  --spiece_model_file=spiece.model \\\n","  --model_config_path=$PRETRAIN_MODEL_DIR/xlnet_config.json \\\n","  --max_seq_length=$MAX_SEQ_LENGTH \\\n","  --train_batch_size=80 \\\n","  --eval_batch_size=80 \\\n","  --num_hosts=1 \\\n","  --num_core_per_host=8 \\\n","  --learning_rate=5e-5 \\\n","  --num_train_epochs=14.0 \\\n","  --warmup_proportion=0.1 \\\n","  --save_steps=1000 \\\n","  --iterations=1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RNsl5XjBvNmj"},"source":["import json\n","with tf.io.gfile.GFile(os.path.join(OUTPUT_DIR, \"paper.logits.json\"), \"r\") as infile:\n","    probabilities = json.load(infile)\n","\n","import numpy as np\n","probabilities = np.asarray(probabilities)\n","\n","# np.save(\"cs-xlnet-{}-valid.npy\".format(\"+\".join(FEATURES)), probabilities)\n","\n","from run_classifier_cs import PaperProcessor\n","journals = PaperProcessor(FEATURES).get_labels()\n","journal_to_idx = {journal:ii for ii, journal in enumerate(journals)}\n","\n","y_valid = []\n","for item in open(os.path.join(DATA_DIR, \"valid.jsonl\")):\n","    item = json.loads(item)\n","    do_skip = False\n","    for feature in FEATURES:\n","        if feature not in item or type(item[feature]) != str or \\\n","            len(item[feature]) < 1: do_skip = True\n","    if not do_skip:\n","        y_valid.append(journal_to_idx[item['journal'].lower()])\n","y_valid = np.asarray(y_valid)\n","\n","print(np.mean(np.repeat(y_valid, 1).reshape(-1,1) == np.argsort(probabilities, axis=-1)[:,:-2:-1])*1)\n","print(np.mean(np.repeat(y_valid, 3).reshape(-1,3) == np.argsort(probabilities, axis=-1)[:,:-4:-1])*3)\n","print(np.mean(np.repeat(y_valid, 5).reshape(-1,5) == np.argsort(probabilities, axis=-1)[:,:-6:-1])*5)\n","print(np.mean(np.repeat(y_valid, 10).reshape(-1,10) == np.argsort(probabilities, axis=-1)[:,:-11:-1])*10)"],"execution_count":null,"outputs":[]}]}